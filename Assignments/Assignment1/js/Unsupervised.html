<!DOCTYPE html>
<html>

<head>
    <link rel="stylesheet" type="text/css" href="../css/main.css">
    <title> </title>
    <h1>Unsupervised Learning</h1>
</head>

<body>
    <div>
        <!--Navigation Menu-->
        <ul class="nav">
            <li><a href="Main.html">Main</a></li>
            <li><a href="Supervised.html">Supervised</a></li>
            <li><a href="Unsupervised.html">Unsupervised</a></li>
            <li><a href="Reinforcement.html">Reinforcement</a></li>
        </ul>
    </div>
    <div>
        <!--Page Content-->
        <p>Unsupervised learning is the machine learning task of predicting a function to describe obnubilated structure from unlabeled data. Since the examples given to the learner are unlabeled, there is no signal to distinguish between how right or wrong
            a solution is. This distinguishes unsupervised learning from supervised learning and reinforcement learning.</p>
    </div>
    <div>
        <img src="../img/th.jpg" class="SLDC">
    </div>
    <div>
        <p>Unsupervised learning is proximately cognate to the quandary of density estimation in statistics. However unsupervised learning withal encompasses many other techniques that seek to summarize and explicate key features of the data. Many methods
            employed in unsupervised learning are predicated on data mining methods used to preprocess data.
        </p>
        <p>Among neural network models, the self-organizing map (SOM) and adaptive resonance theory (ART) are commonly used unsupervised learning algorithms. The SOM is a topographic organization in which nearby locations in the map represent inputs with
            kindred properties. The ART model sanctions the number of clusters to vary with quandary size and lets the utilizer control the degree of homogeneous attribute between members of the same clusters by designates of a utilizer-defined constant
            called the vigilance parameter. ART networks are withal utilized for many pattern apperception tasks, such as automatic target apperception and seismic signal processing. The first version of ART was "ART1", developed by Carpenter and Grossberg.
        </p>
        <p>One of the approaches in unsupervised learning is the method of moments. In the method of moments, the unknown parameters (of interest) in the model are cognate to the moments of one or more desultory variables, and thus, these unknown parameters
            can be estimated given the moments. The moments are conventionally estimated from samples in an empirical way. The rudimentary moments are first and second order moments. For an arbitrary vector, the first order moment is the mean vector,
            and the second order moment is the covariance matrix (when the mean is zero). Higher order moments are conventionally represented utilizing tensors which are the generalization of matrices to higher orders as multi-dimensional arrays. In particular,
            the method of moments is shown to be efficacious in learning the parameters of latent variable models.Latent variable models are statistical models where in integration to the observed variables, a set of latent variables withal subsists which
            is not observed. A highly practical example of latent variable models in machine learning is the topic modeling which is a statistical model for engendering the words (observed variables) in the document predicated on the topic (latent variable)
            of the document. In the topic modeling, the words in the document are engendered according to different statistical parameters when the topic of the document is transmuted. It is shown that method of moments (tensor decomposition techniques)
            consistently instaurate the parameters of an astronomically immense class of latent variable models under some posits.The Expectation-maximization algorithm (EM) is withal one of the most practical methods for learning latent variable models.
            However, it can get stuck in local optima, and it is not ensured that the algorithm will converge to the true unknown parameters of the model. Alternatively, for the method of moments, the ecumenical convergence is assured under some conditions.</p>
    </div>
    <!--Source-->
    <h5 align="left">Sources</h5>
    <div>
        <ul class="navAlgo">
            <li><a href="https://en.wikipedia.org/wiki/Unsupervised_learning">Unsupervised Learning</a></li>
        </ul>
    </div>
</body>

</html>